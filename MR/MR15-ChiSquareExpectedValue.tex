\begin{frame}
\frametitle{Chi-Square Test of Association}

\Large
Expected Value for a Cell

\[ = \frac{\mbox{Column Total}  \times \mbox{Row Total} } {\mbox{Overall Total}}  \]

\end{frame}
%---------------------------------------------%

\begin{frame}
\frametitle{Chi-Square Test of Association}

\Large


 
Chi-Square Tests for independence.
 
Contingency tables are used to examine the relationship between scores on two qualitative or categorical variables for the subjects of a study. Statistical procedures known as Chi-Square Tests for independence are used to test the relationship between these variables.
 
For example, consider the hypothetical experiment on the effectiveness of early childhood intervention programs.
 
In the experimental group, 73 of 85 students graduated from high school. In the control group, only 43 of 82 students graduated. These data are depicted in the contingency table shown below. 
 
 
 
Graduated
Failed to
Graduate
Total
Experimental
73
12
85
Control
43
39
82
Total
116
51
167
The cell entries are cell frequencies. The top left cell with a "73" in it means that 73 subjects in the experimental condition went on to graduate from high school; 12 subjects in the experimental condition did not.
 
An inspection of the contingency table shows that subjects in the experimental condition were more likely to graduate than were subjects in the control condition. Thus, the column a subject is in (graduated or failed to graduate) is contingent upon (depends on) the row the subject is in (experimental or control condition). 
 
Null hypothesis
 
The test of whether the columns are contingent on the rows is called the chi square test of independence. The null hypothesis is that there is no relationship between row and column frequencies.
 
For this example, this is equivalent to saying that the intervention program has no effects on a students performance ; students from both groups are equally as likely to graduate, and that the program does not improve the chance of graduating.
 
If the columns are not contingent on the rows, then the rows and column frequencies are independent. If this was the case, on average an equal proportion would graduate and fail fron both experimental and control groups. Under this hypothesis, any differences between the observation and the expected values can be attributed to the random sampling effects.
 
Alternative hypothesis
 
As always, the alternative hypothesis is the opposite of the null hypothesis, that there is a relationship between row and column frequencies.
This is equivalent to saying that the intervention program does have an effect on a students performance; that the program does indeed improve the chance of graduating. 
 
A statistical procedure is carried out to determine the p-value associated with this test. A decision to reject the null hypothesis is based on this p-value.
 
Expected values
 
The first step in computing the chi square test of independence is to compute the expected frequency for each cell under the assumption that the null hypothesis is true. To calculate the expected frequency of the first cell in the example (experimental condition, graduated), first calculate the proportion of subjects that graduated without considering the condition they were in. The table below shows that of the 167 subjects in the experiment, 116 graduated.
 
Therefore, 116/167 graduated. If the null hypothesis were true, the expected frequency for the first cell would equal the product of the number of people in the experimental condition (85) and the proportion of people graduating (116/167). This is equal to (85)(116)/167 = 59.042. Therefore, the expected frequency for this cell is 59.042. The general formula for expected cell frequencies is:
 
  
where
 
Eij is the expected frequency for the cell in the ith row and the jth column
Tiis the total number of subjects in the ith row
Tj is the total number of subjects in the jth column
N is the total number of subjects in the whole table. 

 
Once the expected cell frequencies are computed, it is convenient to enter them into the original table as shown below. The expected frequencies are in brackets. 
 
 
 
Graduated
Failed to
Graduate
Total
Experimental
73
(59.042)
12
(25.958)
85
Control
43
(56.958)
 
39
(25.042)
82
Total
116
51
167
The formula for chi square test for independence is 
 
 
 
Degrees of Freedom 
The degrees of freedom are equal to (R-1)(C-1) where R is the number of rows and C is the number of columns. In this example, R = 2 and C = 2, so df = (2-1)(2-1) = 1.
 
The chi square test statistic is compared to a critical value of the chi-square distribution with degrees of freedom (R-1)(C-1). This is a one tailed test. The null hypothesis is rejected if the test statistic is greater than the critical value. Alternatively a p-value will be computed and compared to a pre-specified significance level.
 
A computational procedure will determine that for df = 1, a chi square test statistic of 22.01 has a probability value less than 0.0001.
 
 
The results for the example on the effects of the early childhood intervention example could be reported as follows:
The proportion of students from the early-intervention group who graduated from high school was 0.86 whereas the proportion from the control group who graduated was only 0.52. The difference in proportions is significant, χ²(1, N = 167) = 22.01, p < 0.001.
 
Example 2 
 
The same procedures are used for analyses with more than two rows and/or more than two columns. For example, consider the following hypothetical experiment: A drug that decreases anxiety is given to one group of subjects before they attempted to play a game of chess against a computer. The control group was given a placebo. The contingency table is shown below, with expected values in brackets.
 
Condition
Win
Lose
Draw
Total
Drug
12
(14.29)
18
(14.29)
10
(11.43)
40
Placebo
13
(10.71)
7
(10.71)
10
(8.57)
30
Total
25
25
20
70
 
As in the previous example, each expected frequency is computed by multiplying the row total by the column total and dividing by the total number of subjects.
 
For example, the expected frequency for the "Drug-Lose" condition is the product of the row total (40) and the column total (25) divided by the total number of subjects (70): (40)(25)/70 = 14.29. 
 
 
The chi square is calculated using the formula:
 
 
 
 
 
The df are (R-1)(C-1) = (2-1)(3-1) = 2.

 
A chi square table shows that the probability of a chi square of 3.52 with 2 degrees of freedom is 0.172. Therefore, the effect of the drug is not significant. 
 
 The experiment on the effect of the anti-anxiety drug on chess playing could be reported as:
The number of subjects winning,losing,and drawing as a function of drug condition is shown in figure below. Although subjects receiving the drug performed slightly worse than subjects not receiving the drug, the difference was not significant, χ²(2, N = 70) = 3.52, p = 0.17. 
 
 

Comments on the Chi-square test 
 
The formula for chi square yields a statistic that is only approximately a chi square distribution. In order for the approximation to be adequate, the total number of subjects should be at least 20.
 
Some authors claim that the correction for continuity should be used whenever an expected cell frequency is below 5. Research in statistics has shown that this practice is not advisable.
 
 
Other Important tests: 
 
1) Hypothesis test for regression coefficients and correlation.
 
For all types of correlation, there is an associated hypothesis test to examine whether or not the true value of a parameter is zero. This is particularly important in the case of the slope. If the true value is zero, this means that no relationship exists between the independent variable and dependent variable.
 
    
 
In several scientific analyses (e..g calibration studies) , it is important to test whether the true value of the intercept. The test is formulated as follows. 
 
    
 
Necessarily the test for pearon's correlation is the equivalent of the test of the slope. The null hypothesis is that the true value is zero, against the alternative hypothesis which states that it is not zero.
 
    
 
The decision to reject or fail to reject is based on the p-value. 
 
 
2)  F-Test for Equality of Two Standard Deviations.
 
An F-test is used to test if the standard deviations of two populations are equal. 
The two-tailed version tests against the alternative that the standard deviations are not equal. The one-tailed version only tests in one direction, that is the standard deviation from the first population is either greater than (or less than ) the second population standard deviation .
 
 
 
Levene's test is used to test if multiple samples have equal variances. Equal variances across samples is called homogeneity of variance.
 

 
Ha:ij  for some i and j
 
The simple two-sample test for means  is based on the assumption of equal variance of both samples. If the variances are not the same, the analysis for the two-sample must vary accordingly.
 
 
3) Tests for distributions
 
The Kolmorgorov-Smirnov test and the Anderson-Darling test are formulated as follows:
 
         Ho:  The data follows a specified distribution.  
         Ha:  The data do not follow the specified distribution 
 
These tests are one-sided test and the hypothesis that the distribution is of a specific form is rejected if the test statistic is greater than the critical value. They are commonly used to assess whether a data set is normally distributed.
 
The Shapiro-Wilk test is another procedure which specifically tests for the normal distribution
 
         Ho:  The data follows the normal distribution.  
         Ha:  The data do not follow the normal distribution 



\end{frame}
%---------------------------------------------%
\begin{frame}
\frametitle{Chi-Square Test of Association}

\Large
Compute the Expected values for each cell in the following table.
One of the expected values (both A and Y) is given.

 & Cat X & Cat Y & Cat Z & Total  \\ \hline
Cat A & & 60 &  & 200\\ \hline
Cat B & &  &  & 400 \\ \hline
Total & 150 & 180 & 270 &  \textbf{600}\\ \hline
\end{frame}
%---------------------------------------------%
\begin{frame}
\frametitle{Chi-Square Test of Association}
% Writing

\huge


 & Cat X & Cat Y & Cat Z & Total  \\ \hline
Cat A & \phantom{space}& 60 &  & 200\\ \hline
Cat B & \phantom{space}& \phantom{space} & \phantom{space} & 400 \\ \hline
Total & 150 & 180 & 270 &  \textbf{600}\\ \hline

\end{frame}
%---------------------------------------------%

\begin{frame}
\frametitle{Chi-Square Test of Association}

\textbf{Cell$_{(1,1)}$}\
\begin{itemize}
\item Row 1 : Row Total = 200
\item Column 1 : Column Total - 150
\item (Overall Total = 600)
\end{itemize}

Expected value for Cell$_{(1,1)}$

\[ E_{(1,1)} = frac{200 \times 150}{600} = \frac{30,000}{600} = 50 \]
\end{frame}
%---------------------------------------------%
\begin{frame}
\frametitle{Chi-Square Test of Association}
% Writing

\huge


 & Cat X & Cat Y & Cat Z & Total  \\ \hline
Cat A & 50 & 60 &  & 200\\ \hline
Cat B & \phantom{space}& \phantom{space} & \phantom{space} & 400 \\ \hline
Total & 150 & 180 & 270 &  \textbf{600}\\ \hline

\end{frame}

%---------------------------------------------%

\begin{frame}
\frametitle{Chi-Square Test of Association}

\textbf{Cell$_{(2,1)}$}\
\begin{itemize}
\item Row 2 : Row Total = 400
\item Column 1 : Column Total - 150
\item (Overall Total = 600)
\end{itemize}

Expected value for Cell$_{(2,1)}$

\[ E_{(2,1)} = frac{400 \times 150}{600} = \frac{60,000}{600} = 100 \]
\end{frame}
%---------------------------------------------%
\begin{frame}
\frametitle{Chi-Square Test of Association}
% Writing

\huge


 & Cat X & Cat Y & Cat Z & Total  \\ \hline
Cat A & 50 & 60 &  & 200\\ \hline
Cat B & \phantom{s}100\phantom{s}& \phantom{space} & \phantom{space} & 400 \\ \hline
Total & 150 & 180 & 270 &  \textbf{600}\\ \hline

\end{frame}
%---------------------------------------------%
